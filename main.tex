\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[english]{babel}
\usepackage{gensymb}

\begin{document}
	\section{Definitions}
		\subsection{Complex Numbers}
			\subsubsection{Absolute Value and Argument}
			The absolute value of a complex number is the distance to the origin. The absolute value of a complex number $z=a+bi$ is denoted by $|z|$, and equals $\sqrt{a^2+b^2}$.
			
			The argument is the angle the directed segment from the origin to the complex numbers makes with the positive real axis. The argument is only defined for nonzero complex numbers.
			
			From the absolute value and argument it is straightforward to find it's real and imaginary parts:
			\begin{eqnarray*}
				Re(z) &=& |z|\cos{(\arg{z})} \\
				Im(z) &=& |z|\sin{(\arg{z})}
			\end{eqnarray*}
			\subsubsection{Real part and imaginary part}
			If $z = a+bi$ with $a,b \in \mathbb{R}$, then $a$ is called the real part of $z$ denoted by $Re(z)$, and b is called the imaginary part of z, denoted by $Im(z)$.
			
			For instance for all $z_1,z_2$ we have:
			\begin{eqnarray*}
				Re(z_1+z_2) &=& Re(z_1) + Re(z_2) \\
				Im(z_1+z_2) &=& Im(z_1) + Im(z_1) \\
				Re(z_1z_2) &=& Re(z_1)Re(z_2) - Im(z_1)Im(z_2) \\
				Im(z_1z_2) &=& Re(z_1)Im(z_2) + Im(z_1)Re(z_2) \\
			\end{eqnarray*}
		
			\subsubsection{Triangle inequality}
			\begin{equation*}
				|z + w| \leq |z| + |w|
			\end{equation*}
			
			\subsubsection{The complex conjugate}
			If $z = a+bi$ with $a,b \in \mathbb{R}$ is a complex number, then $a-bi$ is called the complex conjugate of $z$, denoted by $\overline{z}$. Geometrically speaking, conjugation is a reflection in the real axis.
			
			\subsubsection{Complex exponential function}
			For very complex number $z$ we define the complex number $e^z$ by giving its absolute value and argument:
			\begin{eqnarray*}
				|e^z| &=& e^{Re(z)}, \\
				\arg{e^z} &=& Im(z)
			\end{eqnarray*}
		
			\subsubsection{Complex sine and cosine}
			\begin{eqnarray*}
				\cos{z} &=& \frac{1}{2}(e^{iz} + e^{-iz}), \\
				\sin{z} &=& \frac{1}{2i}e^{iz} - e^{-iz})
			\end{eqnarray*}
		
			\subsubsection{Complex polynomial}
			An expression in the form
			\begin{equation*}
				a_nz^n + a{n-1}z^{n-1} + \dots + a_1z+a_0
			\end{equation*}
			
			in which $a_0,\dots,a_n$ are complex numbers, is called a complex polynomial. Let $p(z)$ be a polynomial. If $p(\alpha) = 0$, then $\alpha$ is called a zero or root of the polynomial.
			
			\subsubsection{Lines and segments of the (complex) plane}
			If $z \neq 0$ is a complex number, then the numbers $tz$ with, $t \in \mathbb{R}$, describe the line through $0$ and $z$. The segment with the endpoints $0$ and $z$ is described by taking $t$ in the interval $[0,1]$. We sometimes denote this segment by $[0,z]$. The midpoint of the segment $[0,z]$ is the complex number $\frac{1}{2}z$. For $t = \frac{1}{2}$. we find the midpoint of $[z,w]$:
			\begin{equation*}
				w + \frac{1}{2}(z-w) \text{or} \frac{1}{2}(z+w)
			\end{equation*}
			
			The length of the segment $[z,w]$ is equal to the distance between $z$ and $w$, i.e., $|w-z|$.
			
			The lines through $z_1$ and $z_2$ (with $z_1 \neq z_2$) and through $w_1$ and $w_2$ with ($w_1 \neq w_2)$, respectively, are parallel if and only if $w_2 - w_1$ is a real multiple of $z_2-z_1$, or, equivalently, the quotient $\frac{w_2-w_1}{z_2-z_1} \in \mathbb{R}$
			
			\subsubsection{Translations}
			Let $u$ be a complex number. The map $T: \mathbb{C} \to \mathbb{C}$ given by $T(z) = z+u$ is a translation over $u$. Translations 'preserve shapes', so, for example, they transform straight lines into straight lines.

		\subsection{Vectors in two and three dimensions}
			\subsubsection{Linear combinations}
			If $\vec{v_1},\vec{v_2},,..,\vec{v_k}$ are $k$ vectors and $\lambda_1,\dots,\lambda_k$ are $k$ real numbers (scalars), then the vector:
			\begin{equation*}
				\lambda_1\vec{v_1} + \lambda_2+\vec{v_2} + \dots + \lambda_k+\vec{v_k}
			\end{equation*}
			is called a linear combination of these vectors.
			
			\subsubsection{Length}
			The length of $\vec{x}$ is denoted by $||x||$. The distance between the two vectors $\vec{u}$ and $\vec{v}$ is by defenition the length of the difference $\vec{u}- \vec{v}$ (or $\vec{v} - \vec{u}$), so $||\vec{u} - \vec{v}||$.
			
			\subsubsection{The inner product}
			The inner product of two vectors $\vec{u}$ and $\vec{v}$, both $\vec{0}$, is defined as
			\begin{equation*}
				||\vec{u}|| \cdot ||\vec{v}|| \cdot \cos{\rho}.
			\end{equation*}
			The inner product is denoted by $(\vec{u}, \vec{v})$.
			
		\subsubsection{Orthogonality}
		If two non-zero vector have inner product 0, then they are perpendicular (the angle between them is $\pm 90\degree$ or $\pm\frac{\pi}{2})$ since the cosine of the angle between them is 0. conversely, if two non-zero vectors are perpendicular then their inner product is 0. Now the zero vector has inner product 0 with any vector, and we agree to say that the zero vector is perpendicular to any vector. This is a convenient convention since then we have: The inner product of two vectors is 0 if and only if the vectors are perpendicular.
		
		\subsubsection{Cross product}
		The cross product of $\vec{v}\times\vec{u}$ of the vectors $\vec{v} = (v_1, v_2, v_3)$ and $\vec{w} = (w_1, w_2, w_3)$ is by definition the vector
		\begin{equation*}
			(v_2w_3 - v_3w_2, v_3w_1 - v_1w_3, v_1w_2 - v_2w_1).
		\end{equation*}
		The cross product always gives a vector perpendicular to $\vec{u}$ and $\vec{w}$.
		
		\subsection{Matrices and systems of linear equations}
			\subsubsection{Matrix}
			A matrix is a rectangular array of numbers or elements from some arithmetical structure.
			
			\subsubsection{The opposite matrix}
			The matrix $B = (-1)A$ satisfies $A+B=0$ and is called the $(additive) opposite of A$. Instead of $(-1)A$ we usually write $-A$.
			
			\subsubsection{The identity matrix}
			The $n\times n$-matrix.
			\begin{equation*}
				I = \begin{pmatrix}
					1 && 0 && \dots && 0 \\
					0 && 1 && \ddots && \vdots\\
					\vdots && \ddots && \ddots && 0 \\
					0 && \dots && 0 && 1
				\end{pmatrix}
			\end{equation*}
			
			\subsubsection{The (multiplicative) inverse of a matrix}
			If, given a $n\times n$-matrix A, there exists a matrix $n\times n$ B with $AB = BA = I$ then B is called the inverse of A. We usually denote this inverse by $A^{-1}$. Keep in mind that there also exist non-zero matrices without an inverse.
			
			\subsubsection{Inverse of B and A}
			Let $A$ and $B$ be $n \times n$-matrices and suppose that $A^{-1}$ and $B^{-1}$ exist. Then 
			\begin{equation*}
				(AB)^{-1} = B^{-1}A^{-1}
			\end{equation*}
			
			\subsubsection{Transpose of a matrix}
			If $A = (a_{ij})$ is a $n \times m$-matrix, then its transpose $A^T$ is the $m \times n$ matrix, whose $i$-th row equals the $i$-th column of A (for $i$ = 1, \dots, m), so the $i,j$-th entry of $A^T$ equals $a_{ji}$. The $j$-th column is then automatically equal to the $j$-th row of A.
			
			
\end{document}